{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9233178,"sourceType":"datasetVersion","datasetId":5584755}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q --no-cache-dir torch-geometric","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-24T05:38:41.923158Z","iopub.execute_input":"2024-08-24T05:38:41.923601Z","iopub.status.idle":"2024-08-24T05:38:57.564402Z","shell.execute_reply.started":"2024-08-24T05:38:41.923559Z","shell.execute_reply":"2024-08-24T05:38:57.563200Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\nimport os\nimport random\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom typing import Dict, List, Tuple\n     \nfrom scipy.spatial.distance import cdist\nfrom skimage.measure import regionprops_table, label\nfrom skimage.color import rgb2gray\nfrom skimage.measure import regionprops\nfrom skimage import exposure\nfrom skimage.util import view_as_blocks\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom torchmetrics import Accuracy, F1Score, Recall, Precision\n\nimport torch\nfrom torch import nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch_geometric.nn as geom_nn\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom torchvision import models\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torch_geometric.data import Data, Batch\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom torch_geometric.utils import from_networkx\nfrom torchvision import datasets, transforms\nfrom torch.nn.parallel import DataParallel\n\nimport networkx as nx","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:38:57.566524Z","iopub.execute_input":"2024-08-24T05:38:57.566859Z","iopub.status.idle":"2024-08-24T05:39:05.816304Z","shell.execute_reply.started":"2024-08-24T05:38:57.566823Z","shell.execute_reply":"2024-08-24T05:39:05.815516Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## **Preprocesing and Model Functions**","metadata":{}},{"cell_type":"code","source":"def preprocess_image(image, label):\n    # Convert to float and rescale to [0, 1]\n    image = image.float() / 255.0\n    return image, label\n\ndef sampling(z_mean, z_log_var):\n    epsilon = torch.randn_like(z_mean)\n    return z_mean + torch.exp(0.5 * z_log_var) * epsilon","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:35:41.663098Z","iopub.execute_input":"2024-08-24T05:35:41.663640Z","iopub.status.idle":"2024-08-24T05:35:41.669201Z","shell.execute_reply.started":"2024-08-24T05:35:41.663604Z","shell.execute_reply":"2024-08-24T05:35:41.668200Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Encoder1(nn.Module):\n    def __init__(self):\n        super(Encoder1, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:35:41.671947Z","iopub.execute_input":"2024-08-24T05:35:41.672255Z","iopub.status.idle":"2024-08-24T05:35:41.684767Z","shell.execute_reply.started":"2024-08-24T05:35:41.672221Z","shell.execute_reply":"2024-08-24T05:35:41.683993Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Encoder2(nn.Module):\n    def __init__(self):\n        super(Encoder2, self).__init__()\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv_mean = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n        self.conv_log_var = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n\n    def forward(self, x):\n        x = F.relu(self.conv3(x))\n        x = self.pool(x)\n        x = F.relu(self.conv4(x))\n        x = self.pool(x)\n        z_mean = self.conv_mean(x)\n        z_log_var = self.conv_log_var(x)\n        return z_mean, z_log_var","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:35:41.685836Z","iopub.execute_input":"2024-08-24T05:35:41.686118Z","iopub.status.idle":"2024-08-24T05:35:41.696542Z","shell.execute_reply.started":"2024-08-24T05:35:41.686090Z","shell.execute_reply":"2024-08-24T05:35:41.695748Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Decoder1(nn.Module):\n    def __init__(self):\n        super(Decoder1, self).__init__()\n        self.deconv1 = nn.ConvTranspose2d(128, 256, kernel_size=3, padding=1)\n        self.deconv2 = nn.ConvTranspose2d(256, 128, kernel_size=3, padding=1)\n        self.upsample = nn.Upsample(scale_factor=2)\n\n    def forward(self, x):\n        x = F.relu(self.deconv1(x))\n        x = self.upsample(x)\n        x = F.relu(self.deconv2(x))\n        x = self.upsample(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:35:41.697560Z","iopub.execute_input":"2024-08-24T05:35:41.697847Z","iopub.status.idle":"2024-08-24T05:35:41.709087Z","shell.execute_reply.started":"2024-08-24T05:35:41.697816Z","shell.execute_reply":"2024-08-24T05:35:41.708226Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class Decoder2(nn.Module):\n    def __init__(self):\n        super(Decoder2, self).__init__()\n        self.deconv3 = nn.ConvTranspose2d(128, 64, kernel_size=3, padding=1)\n        self.deconv4 = nn.ConvTranspose2d(64, 32, kernel_size=3, padding=1)\n        self.output_layer = nn.ConvTranspose2d(32, 3, kernel_size=3, padding=1)\n        self.upsample = nn.Upsample(scale_factor=2)\n\n    def forward(self, x):\n        x = F.relu(self.deconv3(x))\n        x = self.upsample(x)\n        x = F.relu(self.deconv4(x))\n        x = self.upsample(x)\n        x = torch.sigmoid(self.output_layer(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:35:41.710201Z","iopub.execute_input":"2024-08-24T05:35:41.710558Z","iopub.status.idle":"2024-08-24T05:35:41.719723Z","shell.execute_reply.started":"2024-08-24T05:35:41.710517Z","shell.execute_reply":"2024-08-24T05:35:41.718894Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class VAE(nn.Module):\n    def __init__(self, encoder1, encoder2, decoder1, decoder2):\n        super(VAE, self).__init__()\n        self.encoder1 = encoder1\n        self.encoder2 = encoder2\n        self.decoder1 = decoder1\n        self.decoder2 = decoder2\n\n    def forward(self, x):\n        x = self.encoder1(x)\n        z_mean, z_log_var = self.encoder2(x)\n        z = sampling(z_mean, z_log_var)\n        x = self.decoder1(z)\n        reconstructed = self.decoder2(x)\n        return reconstructed, z_mean, z_log_var","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:35:41.720918Z","iopub.execute_input":"2024-08-24T05:35:41.721268Z","iopub.status.idle":"2024-08-24T05:35:41.730529Z","shell.execute_reply.started":"2024-08-24T05:35:41.721235Z","shell.execute_reply":"2024-08-24T05:35:41.729748Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## **DataLoader**","metadata":{}},{"cell_type":"code","source":"# Define parameters\nroot_dir = \"/kaggle/input/hepatoma-data/Histopathology-Images\"\nbatch_size = 2\nimg_size = 1600\nprefetch_size = 4  # This will translate to `num_workers` in PyTorch\ntrain_split_ratio = 0.8  # 80% for training, 20% for testing\n\n# Image preprocessing: Resizing and normalization (to [0, 1])\ntransform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor()  # Converts images to tensor and scales them to [0, 1]\n])\n\n# Create the full dataset\nfull_dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n\n# Calculate split sizes\ntrain_size = int(train_split_ratio * len(full_dataset))\ntest_size = len(full_dataset) - train_size\n\n# Split the dataset into training and testing sets\ntrain_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n\n# Create DataLoaders for training and testing sets\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=prefetch_size, pin_memory=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=prefetch_size, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:39:05.817426Z","iopub.execute_input":"2024-08-24T05:39:05.817984Z","iopub.status.idle":"2024-08-24T05:39:06.020908Z","shell.execute_reply.started":"2024-08-24T05:39:05.817949Z","shell.execute_reply":"2024-08-24T05:39:06.020151Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## **Training and Testing Steps**","metadata":{}},{"cell_type":"code","source":"def train_step(model: torch.nn.Module,\n               dataloader: torch.utils.data.DataLoader,\n               optimizer: torch.optim.Optimizer,\n               device: torch.device,\n               recon_factor: float = 1.0,\n               kl_factor: float = 1.0) -> float:\n    model.train()\n    train_loss = 0\n\n    for batch, (X, _) in tqdm(enumerate(dataloader), total=len(dataloader)):\n        X = X.to(device)\n\n        # Forward pass\n        reconstructed, z_mean, z_log_var = model(X)\n\n        # Calculate loss\n        loss = vae_loss(reconstructed, X, z_mean, z_log_var, recon_factor, kl_factor)\n        train_loss += loss.item()\n\n        # Zero gradients\n        optimizer.zero_grad()\n\n        # Backward pass\n        loss.backward()\n\n        # Optimizer step\n        optimizer.step()\n\n    # Average loss per batch\n    train_loss /= len(dataloader)\n    return train_loss\n\n\ndef test_step(model: torch.nn.Module,\n              dataloader: torch.utils.data.DataLoader,\n              device: torch.device,\n              recon_factor: float = 1.0,\n              kl_factor: float = 1.0) -> float:\n    model.eval()\n    test_loss = 0\n\n    with torch.no_grad():\n        for batch, (X, _) in tqdm(enumerate(dataloader), total=len(dataloader)):\n            X = X.to(device)\n\n            # Forward pass\n            reconstructed, z_mean, z_log_var = model(X)\n\n            # Calculate loss\n            loss = vae_loss(reconstructed, X, z_mean, z_log_var, recon_factor, kl_factor)\n            test_loss += loss.item()\n\n    # Average loss per batch\n    test_loss /= len(dataloader)\n    return test_loss","metadata":{"execution":{"iopub.status.busy":"2024-08-23T15:07:56.479086Z","iopub.execute_input":"2024-08-23T15:07:56.479367Z","iopub.status.idle":"2024-08-23T15:07:56.491128Z","shell.execute_reply.started":"2024-08-23T15:07:56.479337Z","shell.execute_reply":"2024-08-23T15:07:56.490237Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## **Training Loop**","metadata":{}},{"cell_type":"code","source":"def train(model: torch.nn.Module,\n          train_dataloader: torch.utils.data.DataLoader,\n          test_dataloader: torch.utils.data.DataLoader,\n          optimizer: torch.optim.Optimizer,\n          epochs: int,\n          device: torch.device,\n          recon_factor: float = 1.0,\n          kl_factor: float = 1.0) -> dict:\n\n    results = {\"train_loss\": [],\n               \"test_loss\": []}\n\n    model.to(device)\n\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n\n        # Training step\n        train_loss = train_step(model=model,\n                                dataloader=train_dataloader,\n                                optimizer=optimizer,\n                                device=device,\n                                recon_factor=recon_factor,\n                                kl_factor=kl_factor)\n\n        # Testing step\n        test_loss = test_step(model=model,\n                              dataloader=test_dataloader,\n                              device=device,\n                              recon_factor=recon_factor,\n                              kl_factor=kl_factor)\n\n        print(f\"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}\")\n\n        # Store results\n        results[\"train_loss\"].append(train_loss)\n        results[\"test_loss\"].append(test_loss)\n\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-08-23T15:07:56.492266Z","iopub.execute_input":"2024-08-23T15:07:56.492614Z","iopub.status.idle":"2024-08-23T15:07:56.502129Z","shell.execute_reply.started":"2024-08-23T15:07:56.492573Z","shell.execute_reply":"2024-08-23T15:07:56.501344Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## **Training**","metadata":{}},{"cell_type":"code","source":"def vae_loss(reconstructed, original, z_mean, z_log_var, recon_factor=1.0, kl_factor=1.0):\n    # Reconstruction loss (MSE)\n    reconstruction_loss = nn.functional.mse_loss(reconstructed, original, reduction='sum')\n    \n    # KL divergence loss\n    kl_loss = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp())\n    \n    # Weighted sum of both losses\n    return recon_factor * reconstruction_loss + kl_factor * kl_loss","metadata":{"execution":{"iopub.status.busy":"2024-08-23T15:07:56.503123Z","iopub.execute_input":"2024-08-23T15:07:56.503668Z","iopub.status.idle":"2024-08-23T15:07:56.513271Z","shell.execute_reply.started":"2024-08-23T15:07:56.503636Z","shell.execute_reply":"2024-08-23T15:07:56.512534Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Check for available GPUs\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-23T15:07:56.514319Z","iopub.execute_input":"2024-08-23T15:07:56.514636Z","iopub.status.idle":"2024-08-23T15:07:56.573018Z","shell.execute_reply.started":"2024-08-23T15:07:56.514605Z","shell.execute_reply":"2024-08-23T15:07:56.572055Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize the model and move it to the device\nencoder1 = Encoder1().to(device)\nencoder2 = Encoder2().to(device)\ndecoder1 = Decoder1().to(device)\ndecoder2 = Decoder2().to(device)\nvae = VAE(encoder1, encoder2, decoder1, decoder2).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T15:07:56.574148Z","iopub.execute_input":"2024-08-23T15:07:56.575068Z","iopub.status.idle":"2024-08-23T15:07:56.791814Z","shell.execute_reply.started":"2024-08-23T15:07:56.575033Z","shell.execute_reply":"2024-08-23T15:07:56.791025Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Initialize optimizer\noptimizer = torch.optim.Adam(vae.parameters(), lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T15:07:56.792886Z","iopub.execute_input":"2024-08-23T15:07:56.793184Z","iopub.status.idle":"2024-08-23T15:07:56.797483Z","shell.execute_reply.started":"2024-08-23T15:07:56.793152Z","shell.execute_reply":"2024-08-23T15:07:56.796585Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Optionally set up multi-GPU training\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    vae = DataParallel(vae)\n\n# Number of GPUs being used\nnum_devices = torch.cuda.device_count()\nprint(f\"Number of devices: {num_devices}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-23T15:07:56.798549Z","iopub.execute_input":"2024-08-23T15:07:56.798868Z","iopub.status.idle":"2024-08-23T15:07:56.808389Z","shell.execute_reply.started":"2024-08-23T15:07:56.798838Z","shell.execute_reply":"2024-08-23T15:07:56.807426Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Using 2 GPUs\nNumber of devices: 2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model and store the results in \"history\" variable\nhistory = train(\n    model=vae,\n    train_dataloader=train_dataloader,\n    test_dataloader=test_dataloader,\n    optimizer=optimizer,\n    epochs=256,\n    device=device,\n    recon_factor=1.0,  # Custom weight for reconstruction loss\n    kl_factor=0      # Custom weight for KL divergence\n)     ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-23T15:07:56.809872Z","iopub.execute_input":"2024-08-23T15:07:56.810239Z","iopub.status.idle":"2024-08-23T19:22:33.604721Z","shell.execute_reply.started":"2024-08-23T15:07:56.810186Z","shell.execute_reply":"2024-08-23T19:22:33.603677Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/256\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/135 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n100%|██████████| 135/135 [00:48<00:00,  2.76it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.58it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 559776.6056 | Test Loss: 364430.4439\nEpoch 2/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:49<00:00,  2.74it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.85it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 229940.1732 | Test Loss: 175648.5551\nEpoch 3/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.69it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.42it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 148341.2143 | Test Loss: 139991.3348\nEpoch 4/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.68it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 117196.1322 | Test Loss: 107199.7415\nEpoch 5/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.69it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.96it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 99167.8275 | Test Loss: 94269.1608\nEpoch 6/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.68it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.69it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 85927.4749 | Test Loss: 83141.1272\nEpoch 7/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 78397.7524 | Test Loss: 83908.1531\nEpoch 8/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.83it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 73502.1922 | Test Loss: 73854.1469\nEpoch 9/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.68it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.95it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 69313.5503 | Test Loss: 68699.3172\nEpoch 10/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 65737.6273 | Test Loss: 62813.2341\nEpoch 11/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.82it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 62648.4849 | Test Loss: 61331.2148\nEpoch 12/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.68it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.87it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 58394.6374 | Test Loss: 59772.5952\nEpoch 13/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.68it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.55it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 56208.9576 | Test Loss: 58686.5337\nEpoch 14/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.68it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.62it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 54838.1664 | Test Loss: 54068.0854\nEpoch 15/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.75it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 51922.2570 | Test Loss: 51774.5805\nEpoch 16/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.85it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 50817.0830 | Test Loss: 51804.7256\nEpoch 17/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.68it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.97it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 49413.9248 | Test Loss: 49036.3093\nEpoch 18/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.78it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 50717.8523 | Test Loss: 47976.4841\nEpoch 19/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.81it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 46705.2208 | Test Loss: 46975.8942\nEpoch 20/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.84it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 48866.8807 | Test Loss: 45792.3213\nEpoch 21/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.79it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 44620.4718 | Test Loss: 44216.2052\nEpoch 22/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.75it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 44775.5245 | Test Loss: 46500.5609\nEpoch 23/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.73it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 43049.0660 | Test Loss: 43125.6979\nEpoch 24/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.86it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 44658.5878 | Test Loss: 41708.1228\nEpoch 25/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.83it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 40916.6997 | Test Loss: 40807.8039\nEpoch 26/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.76it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 41388.9613 | Test Loss: 45335.6406\nEpoch 27/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.90it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 39834.6657 | Test Loss: 39284.6293\nEpoch 28/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  4.00it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 39009.6185 | Test Loss: 38478.3424\nEpoch 29/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.68it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 38322.3694 | Test Loss: 37741.7119\nEpoch 30/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.60it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 38265.3948 | Test Loss: 45055.2417\nEpoch 31/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.98it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 38659.4108 | Test Loss: 36498.8590\nEpoch 32/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 37153.7850 | Test Loss: 36250.6236\nEpoch 33/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.84it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 35868.9859 | Test Loss: 35648.3863\nEpoch 34/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.95it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 35080.3397 | Test Loss: 36121.0361\nEpoch 35/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.89it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 36393.7932 | Test Loss: 34293.1966\nEpoch 36/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 34259.8917 | Test Loss: 35136.4095\nEpoch 37/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.78it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 34158.0224 | Test Loss: 33606.8085\nEpoch 38/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.78it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 33191.8271 | Test Loss: 35293.9447\nEpoch 39/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.78it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 32969.3520 | Test Loss: 32679.4992\nEpoch 40/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.96it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 32325.6942 | Test Loss: 31791.7842\nEpoch 41/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 31826.9111 | Test Loss: 33288.1563\nEpoch 42/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.70it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 31778.5442 | Test Loss: 32249.8879\nEpoch 43/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.99it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 31374.8007 | Test Loss: 31708.2066\nEpoch 44/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.68it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.83it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 38026.8114 | Test Loss: 30889.9582\nEpoch 45/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.94it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 30281.2771 | Test Loss: 30218.0316\nEpoch 46/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.73it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 29827.6735 | Test Loss: 29908.9628\nEpoch 47/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.65it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 29801.4862 | Test Loss: 30063.3623\nEpoch 48/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.98it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 29746.9057 | Test Loss: 30584.5526\nEpoch 49/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 28894.7878 | Test Loss: 29047.7618\nEpoch 50/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 30311.3806 | Test Loss: 28585.0894\nEpoch 51/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.92it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 28318.3720 | Test Loss: 28500.9884\nEpoch 52/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.84it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 28913.7483 | Test Loss: 30299.1961\nEpoch 53/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.55it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 28682.1417 | Test Loss: 29531.0970\nEpoch 54/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  4.17it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 28339.6558 | Test Loss: 27702.1538\nEpoch 55/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.71it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 27901.8450 | Test Loss: 27277.5601\nEpoch 56/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.81it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 26925.5186 | Test Loss: 26875.3262\nEpoch 57/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.76it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 27756.8753 | Test Loss: 26877.5669\nEpoch 58/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.60it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 26808.5250 | Test Loss: 27807.1618\nEpoch 59/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 27304.9917 | Test Loss: 26189.3689\nEpoch 60/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.65it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 27561.7505 | Test Loss: 28017.4716\nEpoch 61/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.65it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 26111.2727 | Test Loss: 25790.0485\nEpoch 62/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.78it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 25608.2797 | Test Loss: 25446.9233\nEpoch 63/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 26135.5721 | Test Loss: 25448.3550\nEpoch 64/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.87it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 26814.8071 | Test Loss: 26158.2315\nEpoch 65/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.91it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 25441.2134 | Test Loss: 25113.0389\nEpoch 66/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.79it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 24693.2416 | Test Loss: 24521.1303\nEpoch 67/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.83it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 24410.2251 | Test Loss: 25861.0997\nEpoch 68/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.79it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 25089.5961 | Test Loss: 25824.8357\nEpoch 69/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.67it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 25523.2031 | Test Loss: 28645.7921\nEpoch 70/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.86it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 24061.5533 | Test Loss: 23911.2259\nEpoch 71/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.95it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 24519.2777 | Test Loss: 26045.2980\nEpoch 72/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.96it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 23880.4219 | Test Loss: 23449.9996\nEpoch 73/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.96it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 23414.4899 | Test Loss: 24514.7206\nEpoch 74/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.92it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 23981.5555 | Test Loss: 23132.0932\nEpoch 75/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.92it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 22691.3484 | Test Loss: 22712.4987\nEpoch 76/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 22777.1536 | Test Loss: 22796.0127\nEpoch 77/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.58it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 27096.8850 | Test Loss: 24428.8501\nEpoch 78/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.81it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 23001.4752 | Test Loss: 31625.5546\nEpoch 79/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.97it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 23519.7869 | Test Loss: 22398.7389\nEpoch 80/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  4.03it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 23131.5951 | Test Loss: 28199.5728\nEpoch 81/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 22645.2291 | Test Loss: 22252.7770\nEpoch 82/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.91it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 21811.1414 | Test Loss: 21887.1003\nEpoch 83/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.97it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 21666.1161 | Test Loss: 21716.4207\nEpoch 84/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.85it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 22955.8337 | Test Loss: 21676.7844\nEpoch 85/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.84it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 21498.7133 | Test Loss: 21504.0088\nEpoch 86/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.95it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 21687.5396 | Test Loss: 21752.2474\nEpoch 87/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.63it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 21269.1976 | Test Loss: 21160.0071\nEpoch 88/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 22302.6241 | Test Loss: 26354.3015\nEpoch 89/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.94it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 21681.7487 | Test Loss: 20955.9332\nEpoch 90/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.85it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 21005.1828 | Test Loss: 21995.7667\nEpoch 91/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 21711.9177 | Test Loss: 21469.7905\nEpoch 92/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.84it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 21372.7055 | Test Loss: 21044.2973\nEpoch 93/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.75it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 20631.4331 | Test Loss: 21889.2159\nEpoch 94/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.75it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 21594.1575 | Test Loss: 21314.3209\nEpoch 95/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 21013.1864 | Test Loss: 20356.2830\nEpoch 96/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.73it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 20038.7445 | Test Loss: 20086.2654\nEpoch 97/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  4.02it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 20805.5263 | Test Loss: 21028.7065\nEpoch 98/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 21329.8593 | Test Loss: 20151.4393\nEpoch 99/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.67it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19788.4577 | Test Loss: 19848.3628\nEpoch 100/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.79it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19924.4551 | Test Loss: 19951.3041\nEpoch 101/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.68it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19660.9365 | Test Loss: 19527.8795\nEpoch 102/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 20604.6671 | Test Loss: 19848.8365\nEpoch 103/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.91it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19704.2198 | Test Loss: 19635.3487\nEpoch 104/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.75it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19768.5752 | Test Loss: 19656.2860\nEpoch 105/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.78it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19525.1537 | Test Loss: 30362.2019\nEpoch 106/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.82it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 24855.5720 | Test Loss: 19651.2807\nEpoch 107/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.97it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19111.3107 | Test Loss: 19159.7111\nEpoch 108/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.81it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18951.8137 | Test Loss: 19089.7565\nEpoch 109/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.84it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19082.6960 | Test Loss: 19339.2682\nEpoch 110/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.74it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18988.9577 | Test Loss: 24586.6644\nEpoch 111/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.99it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 20233.5916 | Test Loss: 18760.4697\nEpoch 112/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.87it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18684.4188 | Test Loss: 18836.2829\nEpoch 113/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  4.04it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19053.8049 | Test Loss: 20038.6514\nEpoch 114/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.83it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18774.8498 | Test Loss: 18796.2705\nEpoch 115/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.73it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19167.3577 | Test Loss: 18690.1678\nEpoch 116/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.82it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18605.7626 | Test Loss: 18537.8165\nEpoch 117/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.61it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18875.3358 | Test Loss: 19669.8912\nEpoch 118/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.73it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19109.6684 | Test Loss: 21756.8846\nEpoch 119/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.85it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19169.3458 | Test Loss: 18320.2219\nEpoch 120/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.91it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18205.3909 | Test Loss: 18502.6297\nEpoch 121/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19312.1519 | Test Loss: 18577.3202\nEpoch 122/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18089.2905 | Test Loss: 18018.5217\nEpoch 123/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.78it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18462.1299 | Test Loss: 20456.7403\nEpoch 124/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.92it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18125.0116 | Test Loss: 18211.2676\nEpoch 125/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18220.3080 | Test Loss: 18251.4738\nEpoch 126/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.86it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18827.9026 | Test Loss: 19510.0605\nEpoch 127/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18065.4679 | Test Loss: 17701.3614\nEpoch 128/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.90it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17924.1746 | Test Loss: 17754.9843\nEpoch 129/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.57it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 19002.2884 | Test Loss: 20469.1367\nEpoch 130/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.97it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18745.7416 | Test Loss: 17654.6311\nEpoch 131/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.87it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17616.0433 | Test Loss: 18240.3018\nEpoch 132/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.67it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17411.1262 | Test Loss: 17454.8389\nEpoch 133/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.83it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18041.7894 | Test Loss: 17901.1656\nEpoch 134/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.91it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17750.3133 | Test Loss: 17713.2639\nEpoch 135/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.81it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17759.7137 | Test Loss: 17842.5683\nEpoch 136/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.96it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17547.8769 | Test Loss: 17512.2272\nEpoch 137/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.69it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18169.2400 | Test Loss: 18955.5633\nEpoch 138/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.74it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18456.4992 | Test Loss: 17377.3750\nEpoch 139/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.98it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17027.4382 | Test Loss: 17175.7871\nEpoch 140/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.75it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17010.6193 | Test Loss: 17198.4837\nEpoch 141/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.84it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16944.1517 | Test Loss: 17225.1606\nEpoch 142/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.71it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18790.3350 | Test Loss: 18513.7169\nEpoch 143/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.62it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16906.7807 | Test Loss: 16829.4983\nEpoch 144/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16903.9917 | Test Loss: 16986.6782\nEpoch 145/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17308.6036 | Test Loss: 16985.9098\nEpoch 146/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.49it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17063.9604 | Test Loss: 17159.6737\nEpoch 147/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16701.1996 | Test Loss: 16855.3534\nEpoch 148/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.95it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 18503.7778 | Test Loss: 17120.7211\nEpoch 149/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.87it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16914.1467 | Test Loss: 17278.2414\nEpoch 150/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.58it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17087.0984 | Test Loss: 16627.0416\nEpoch 151/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.83it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16469.9558 | Test Loss: 16510.7914\nEpoch 152/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.74it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16512.4092 | Test Loss: 16583.9329\nEpoch 153/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17354.2932 | Test Loss: 16644.3460\nEpoch 154/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16935.1653 | Test Loss: 16700.2811\nEpoch 155/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.91it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16836.2589 | Test Loss: 16692.5035\nEpoch 156/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.74it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16376.6251 | Test Loss: 16338.2295\nEpoch 157/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.78it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16920.8056 | Test Loss: 23340.0281\nEpoch 158/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.74it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16805.5383 | Test Loss: 16247.5430\nEpoch 159/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.67it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16184.3696 | Test Loss: 16111.0614\nEpoch 160/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.89it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16775.2967 | Test Loss: 21568.0659\nEpoch 161/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.91it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16912.2082 | Test Loss: 16223.8219\nEpoch 162/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16078.5744 | Test Loss: 17129.9509\nEpoch 163/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.81it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17568.2039 | Test Loss: 16600.1520\nEpoch 164/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.94it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16208.8742 | Test Loss: 16122.7521\nEpoch 165/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.79it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15982.1059 | Test Loss: 16028.0553\nEpoch 166/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.72it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16296.3274 | Test Loss: 16121.0149\nEpoch 167/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.85it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16043.5221 | Test Loss: 15903.2315\nEpoch 168/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.78it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15995.3188 | Test Loss: 16075.0082\nEpoch 169/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.59it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 17228.3604 | Test Loss: 16104.5519\nEpoch 170/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.56it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16391.1318 | Test Loss: 17679.6359\nEpoch 171/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.73it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15943.3906 | Test Loss: 15771.1526\nEpoch 172/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.98it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16062.6773 | Test Loss: 15930.9377\nEpoch 173/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.80it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15869.6145 | Test Loss: 15981.7366\nEpoch 174/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15676.5810 | Test Loss: 15695.2441\nEpoch 175/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.82it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16554.3249 | Test Loss: 15997.1695\nEpoch 176/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.71it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15994.4907 | Test Loss: 15925.1106\nEpoch 177/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15590.3446 | Test Loss: 15656.2445\nEpoch 178/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.79it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16805.0444 | Test Loss: 15586.7206\nEpoch 179/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.63it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15592.2686 | Test Loss: 15507.4512\nEpoch 180/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.91it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15767.9217 | Test Loss: 15498.1878\nEpoch 181/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15497.5738 | Test Loss: 16875.2524\nEpoch 182/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.94it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16219.8395 | Test Loss: 15483.7120\nEpoch 183/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.87it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15461.1206 | Test Loss: 15593.6636\nEpoch 184/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15810.3439 | Test Loss: 15489.0179\nEpoch 185/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.86it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15289.2138 | Test Loss: 15406.3184\nEpoch 186/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.85it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15301.3642 | Test Loss: 15285.9543\nEpoch 187/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.84it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15908.4535 | Test Loss: 15539.7407\nEpoch 188/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16101.4235 | Test Loss: 15664.4656\nEpoch 189/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.91it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15572.4592 | Test Loss: 15804.4135\nEpoch 190/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.92it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15342.6113 | Test Loss: 15482.1968\nEpoch 191/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.95it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16462.2225 | Test Loss: 16643.3018\nEpoch 192/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  4.01it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15424.2571 | Test Loss: 15441.3721\nEpoch 193/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.86it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15248.0551 | Test Loss: 15265.8018\nEpoch 194/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14969.7218 | Test Loss: 15147.8183\nEpoch 195/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 16983.5606 | Test Loss: 15123.6404\nEpoch 196/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.53it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14931.5494 | Test Loss: 15078.8505\nEpoch 197/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.67it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14971.2703 | Test Loss: 15009.0068\nEpoch 198/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.86it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15323.7489 | Test Loss: 19578.5102\nEpoch 199/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15804.6186 | Test Loss: 15028.1576\nEpoch 200/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.58it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15116.0093 | Test Loss: 15097.1639\nEpoch 201/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.83it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14888.6422 | Test Loss: 14841.9541\nEpoch 202/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.95it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15173.9976 | Test Loss: 16778.8775\nEpoch 203/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.88it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15383.0178 | Test Loss: 14812.6159\nEpoch 204/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.70it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14945.6003 | Test Loss: 16263.8108\nEpoch 205/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15598.9364 | Test Loss: 14880.0792\nEpoch 206/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.84it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14840.9471 | Test Loss: 15214.2840\nEpoch 207/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.80it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14824.5367 | Test Loss: 14862.6181\nEpoch 208/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.90it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14671.8986 | Test Loss: 14626.9216\nEpoch 209/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.80it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15357.8426 | Test Loss: 16125.8246\nEpoch 210/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.89it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14913.3897 | Test Loss: 14741.5902\nEpoch 211/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.92it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15069.2447 | Test Loss: 14631.7573\nEpoch 212/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.92it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14980.7724 | Test Loss: 14583.1693\nEpoch 213/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.75it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15634.0624 | Test Loss: 14528.2217\nEpoch 214/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.83it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14408.7768 | Test Loss: 14552.0889\nEpoch 215/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.76it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14607.4943 | Test Loss: 14703.3518\nEpoch 216/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.89it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14785.8658 | Test Loss: 15780.2660\nEpoch 217/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.94it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14812.8270 | Test Loss: 14531.9141\nEpoch 218/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.99it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14896.4583 | Test Loss: 15196.4027\nEpoch 219/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.89it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14491.7696 | Test Loss: 14400.7755\nEpoch 220/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.99it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14995.4901 | Test Loss: 14800.1403\nEpoch 221/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.86it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14398.6112 | Test Loss: 15129.2801\nEpoch 222/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.68it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14715.2070 | Test Loss: 15400.6067\nEpoch 223/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.85it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14851.9522 | Test Loss: 16524.0957\nEpoch 224/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.87it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14551.2067 | Test Loss: 14247.9071\nEpoch 225/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.92it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14455.8831 | Test Loss: 15117.7007\nEpoch 226/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.82it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14790.7860 | Test Loss: 14410.0657\nEpoch 227/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.91it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14385.7704 | Test Loss: 15002.9634\nEpoch 228/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.95it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15594.9719 | Test Loss: 15246.2484\nEpoch 229/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.76it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14205.5531 | Test Loss: 14121.5373\nEpoch 230/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.96it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14021.5377 | Test Loss: 14245.7021\nEpoch 231/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.76it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14464.6525 | Test Loss: 14394.5563\nEpoch 232/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.73it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14495.4107 | Test Loss: 14686.8309\nEpoch 233/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.76it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14253.8339 | Test Loss: 14089.4882\nEpoch 234/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.67it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.87it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14105.2118 | Test Loss: 14192.5615\nEpoch 235/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.92it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14587.3714 | Test Loss: 14017.9478\nEpoch 236/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.81it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14812.4148 | Test Loss: 14246.1816\nEpoch 237/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.95it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15601.9694 | Test Loss: 15195.7548\nEpoch 238/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.78it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14066.1810 | Test Loss: 13990.2188\nEpoch 239/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  4.00it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 13970.9504 | Test Loss: 14091.7929\nEpoch 240/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.79it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 15022.4668 | Test Loss: 14309.9106\nEpoch 241/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 13832.8591 | Test Loss: 14048.7004\nEpoch 242/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.64it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14648.5794 | Test Loss: 14605.9541\nEpoch 243/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.65it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 13894.8431 | Test Loss: 14068.9866\nEpoch 244/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.84it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 13853.9359 | Test Loss: 14461.2885\nEpoch 245/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.69it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14268.3270 | Test Loss: 13914.6232\nEpoch 246/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.72it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 13832.9396 | Test Loss: 14102.6046\nEpoch 247/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.87it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14316.6203 | Test Loss: 14083.6822\nEpoch 248/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.86it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14623.6637 | Test Loss: 14551.8333\nEpoch 249/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.89it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 13748.5900 | Test Loss: 13695.8935\nEpoch 250/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.63it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 13706.3927 | Test Loss: 13711.6210\nEpoch 251/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.72it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14664.0616 | Test Loss: 13804.1832\nEpoch 252/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.82it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 13626.5009 | Test Loss: 13712.1781\nEpoch 253/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.84it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14080.0465 | Test Loss: 14092.1068\nEpoch 254/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.90it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 13716.8315 | Test Loss: 14416.8218\nEpoch 255/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.66it/s]\n100%|██████████| 34/34 [00:08<00:00,  3.95it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 14527.9317 | Test Loss: 14951.0263\nEpoch 256/256\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 135/135 [00:50<00:00,  2.65it/s]\n100%|██████████| 34/34 [00:09<00:00,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 13826.6195 | Test Loss: 13627.3053\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save Model\ntorch.save(\n        obj=vae.state_dict(),\n        f=f\"/kaggle/working/vae_512.pth\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:22:44.425460Z","iopub.execute_input":"2024-08-23T19:22:44.426191Z","iopub.status.idle":"2024-08-23T19:22:44.445029Z","shell.execute_reply.started":"2024-08-23T19:22:44.426150Z","shell.execute_reply":"2024-08-23T19:22:44.444060Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"history_df = pd.DataFrame(history)\nhistory_df.to_csv(\"/kaggle/working/history-vae_512.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:22:58.871746Z","iopub.execute_input":"2024-08-23T19:22:58.872624Z","iopub.status.idle":"2024-08-23T19:22:58.885796Z","shell.execute_reply.started":"2024-08-23T19:22:58.872579Z","shell.execute_reply":"2024-08-23T19:22:58.884824Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# **Train for Classification**","metadata":{}},{"cell_type":"code","source":"# Step 1: Load the VAE model and weights\nvae = VAE(encoder1=Encoder1(), encoder2=Encoder2(), decoder1=Decoder1(), decoder2=Decoder2())  # Initialize your VAE model\nvae = torch.nn.DataParallel(vae)\nvae.load_state_dict(torch.load('/kaggle/working/vae_512.pth'))  # Load pretrained weights","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:10:14.910487Z","iopub.execute_input":"2024-08-24T05:10:14.910821Z","iopub.status.idle":"2024-08-24T05:10:15.150713Z","shell.execute_reply.started":"2024-08-24T05:10:14.910788Z","shell.execute_reply":"2024-08-24T05:10:15.149802Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2851801847.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  vae.load_state_dict(torch.load('/kaggle/working/vae_512.pth'))  # Load pretrained weights\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# Step 2: Extract the encoder (both Encoder1 and Encoder2)\nclass EncoderForClassification(nn.Module):\n    def __init__(self, encoder1, encoder2, num_classes):\n        super(EncoderForClassification, self).__init__()\n        self.encoder1 = encoder1\n        self.encoder2 = encoder2\n        # Classification head: adjust `encoder_output_size` based on your encoder output\n        self.fc = nn.Sequential(\n            nn.Linear(128 * 100 * 100, 512),  # Adjust the size according to your encoder's output\n            nn.ReLU(),\n            nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, x):\n        x = self.encoder1(x)\n        z_mean, z_log_var = self.encoder2(x)\n        x = z_mean  # We can use `z_mean` as the feature representation\n        x = x.view(x.size(0), -1)  # Flatten the tensor\n        x = self.fc(x)  # Pass through the classification head\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:10:15.151884Z","iopub.execute_input":"2024-08-24T05:10:15.152206Z","iopub.status.idle":"2024-08-24T05:10:15.159248Z","shell.execute_reply.started":"2024-08-24T05:10:15.152173Z","shell.execute_reply":"2024-08-24T05:10:15.158355Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Step 3: Initialize the classification model\nnum_classes = 5  # Set this to the number of classes in your classification task\n\n# If you used DataParallel, access the original model through the `.module` attribute\nmodel = EncoderForClassification(vae.module.encoder1, vae.module.encoder2, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:10:15.160282Z","iopub.execute_input":"2024-08-24T05:10:15.160613Z","iopub.status.idle":"2024-08-24T05:10:20.384702Z","shell.execute_reply.started":"2024-08-24T05:10:15.160557Z","shell.execute_reply":"2024-08-24T05:10:20.383899Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\"\"\"# **Prepare Training Requirements**\"\"\"\n\n# References: https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/engine.py\n\ndef train_step(model: torch.nn.Module,\n               dataloader: torch.utils.data.DataLoader,\n               loss_fn: torch.nn.Module,\n               optimizer: torch.optim.Optimizer,\n               device: torch.device,\n               train_acc_metric,\n               train_f1_metric,\n               train_recall_metric,\n               train_prec_metric) -> Tuple[float, float, float, float, float]:\n\n    model.train()\n\n    train_loss, acc, f1, recall, precision = 0, 0, 0, 0, 0\n\n    for batch, (X, y) in tqdm(enumerate(dataloader)):\n        X, y = X.to(device), y.to(device)\n\n        # Forward pass\n        y_pred = model(X)\n\n        # Calculate and accumulate loss\n        loss = loss_fn(y_pred, y)\n        train_loss += loss.item()\n\n        # Zero gradients\n        optimizer.zero_grad()\n\n        # Backward pass\n        loss.backward()\n\n        # Optimizer step\n        optimizer.step()\n\n        # Update metrics\n        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n        acc += train_acc_metric(y_pred_class, y)\n        f1 += train_f1_metric(y_pred_class, y)\n        recall += train_recall_metric(y_pred_class, y)\n        precision += train_prec_metric(y_pred_class, y)\n\n    # Compute metrics\n    train_loss = train_loss / len(dataloader)\n    train_acc = acc / len(dataloader)\n    train_f1 = f1 / len(dataloader)\n    train_rec = recall / len(dataloader)\n    train_precision = precision / len(dataloader)\n\n    return train_loss, train_acc, train_f1, train_rec, train_precision","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:39:06.023314Z","iopub.execute_input":"2024-08-24T05:39:06.023717Z","iopub.status.idle":"2024-08-24T05:39:06.034325Z","shell.execute_reply.started":"2024-08-24T05:39:06.023673Z","shell.execute_reply":"2024-08-24T05:39:06.033301Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def test_step(model: torch.nn.Module,\n              dataloader: torch.utils.data.DataLoader,\n              loss_fn: torch.nn.Module,\n              device: torch.device,\n              test_f1_metric,\n              test_recall_metric,\n              test_acc_metric,\n              test_prec_metric) -> Tuple[float, float, float, float, float]:\n\n    model.eval()\n\n    test_loss, acc, f1, recall, precision = 0, 0, 0, 0, 0\n\n    with torch.no_grad():\n        for batch, (X, y) in tqdm(enumerate(dataloader)):\n            X, y = X.to(device), y.to(device)\n\n            # Forward pass\n            y_pred = model(X)\n\n            # Calculate and accumulate loss\n            loss = loss_fn(y_pred, y)\n            test_loss += loss.item()\n\n            # Update metrics\n            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n            acc += test_acc_metric(y_pred_class, y)\n            f1 += test_f1_metric(y_pred_class, y)\n            recall += test_recall_metric(y_pred_class, y)\n            precision += test_prec_metric(y_pred_class, y)\n\n    # Compute metrics\n    test_loss = test_loss / len(dataloader)\n    test_acc = acc / len(dataloader)\n    test_f1 = f1 / len(dataloader)\n    test_rec = recall / len(dataloader)\n    test_precision = precision / len(dataloader)\n\n    return test_loss, test_acc, test_f1, test_rec, test_precision","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:39:06.035407Z","iopub.execute_input":"2024-08-24T05:39:06.035731Z","iopub.status.idle":"2024-08-24T05:39:06.045938Z","shell.execute_reply.started":"2024-08-24T05:39:06.035700Z","shell.execute_reply":"2024-08-24T05:39:06.044992Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def train(model: torch.nn.Module,\n          train_dataloader: torch.utils.data.DataLoader,\n          test_dataloader: torch.utils.data.DataLoader,\n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          device: torch.device,\n          patience: int) -> Dict[str, List]:\n\n    # Initialize metrics\n    train_acc_metric = Accuracy(task=\"multiclass\", num_classes=5).to(device)\n    train_f1_metric = F1Score(task=\"multiclass\", average='macro', num_classes=5).to(device)\n    train_recall_metric = Recall(task=\"multiclass\", average='macro', num_classes=5).to(device)\n    train_prec_metric = Precision(task=\"multiclass\", average='macro', num_classes=5).to(device)\n\n    test_acc_metric = Accuracy(task=\"multiclass\", num_classes=5).to(device)\n    test_f1_metric = F1Score(task=\"multiclass\", average='macro', num_classes=5).to(device)\n    test_recall_metric = Recall(task=\"multiclass\", average='macro', num_classes=5).to(device)\n    test_prec_metric = Precision(task=\"multiclass\", average='macro', num_classes=5).to(device)\n\n    results = {\"train_loss\": [],\n               \"train_acc\": [],\n               \"train_f1_score\": [],\n               \"train_recall\": [],\n               \"train_precision\": [],\n               \"val_loss\": [],\n               \"val_acc\": [],\n               \"val_f1_score\": [],\n               \"val_recall\": [],\n               \"val_precision\": []\n    }\n    \n    # Early stopping variables\n    best_val_loss = float('inf')\n    patience_counter = 0\n    best_model_state = None\n\n    model.to(device)\n\n    for epoch in range(epochs):\n        if epoch in [32, 64, 96]:\n            torch.save(\n                obj=model.state_dict(),\n                f=f\"/kaggle/working/epoch_{epoch+1}.pth\"\n            )\n\n        train_loss, train_acc, train_f1_score, train_recall, train_precision = train_step(model=model,\n                                          dataloader=train_dataloader,\n                                          loss_fn=loss_fn,\n                                          optimizer=optimizer,\n                                          device=device,\n                                          train_acc_metric=train_acc_metric,\n                                          train_f1_metric=train_f1_metric,\n                                          train_recall_metric=train_recall_metric,\n                                          train_prec_metric=train_prec_metric)\n\n        test_loss, test_acc, test_f1_score, test_recall, test_precision = test_step(model=model,\n                                  dataloader=test_dataloader,\n                                  loss_fn=loss_fn,\n                                  device=device,\n                                  test_acc_metric=test_acc_metric,\n                                  test_f1_metric=test_f1_metric,\n                                  test_recall_metric=test_recall_metric,\n                                  test_prec_metric=test_prec_metric)\n        \n        \n        print(\n          f\"Epoch: {epoch+1} | \"\n          f\"train_loss: {train_loss:.4f} | \"\n          f\"train_acc: {train_acc:.4f} | \"\n          f\"train_F1_score: {train_f1_score:.4f} | \"\n          f\"train_recall: {train_recall:.4f} | \"\n          f\"train_precision: {train_precision:.4f} | \"\n          f\"val_loss: {test_loss:.4f} | \"\n          f\"val_acc: {test_acc:.4f} | \"\n          f\"val_F1_score: {test_f1_score:.4f} | \"\n          f\"val_recall: {test_recall:.4f} | \"\n          f\"val_precision: {test_precision:.4f}\"\n        )\n\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"train_f1_score\"].append(train_f1_score)\n        results[\"train_recall\"].append(train_recall)\n        results[\"train_precision\"].append(train_precision)\n        results[\"val_loss\"].append(test_loss)\n        results[\"val_acc\"].append(test_acc)\n        results[\"val_f1_score\"].append(test_f1_score)\n        results[\"val_recall\"].append(test_recall)\n        results[\"val_precision\"].append(test_precision)\n        \n        # Early stopping check\n        current_val_loss = results['val_loss'][-1]\n        if current_val_loss < best_val_loss:\n            best_val_loss = current_val_loss\n            best_model_state = model.state_dict()  # Save the best model state\n            patience_counter = 0  # Reset the patience counter\n        else:\n            patience_counter += 1\n            print(f\"Patience counter: {patience_counter}/{patience}\")\n            if patience_counter >= patience:\n                print(\"Early stopping triggered.\")\n                model.load_state_dict(best_model_state)  # Load the best model state\n                return results  # Stop training and return history\n\n    \n    model.load_state_dict(best_model_state)  # Ensure the best model is loaded at the end\n    \n    return results","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:39:06.047136Z","iopub.execute_input":"2024-08-24T05:39:06.047432Z","iopub.status.idle":"2024-08-24T05:39:06.069186Z","shell.execute_reply.started":"2024-08-24T05:39:06.047401Z","shell.execute_reply":"2024-08-24T05:39:06.068274Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Initialize optimizer, loss and device to train on\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))\nloss = nn.CrossEntropyLoss()\npatience=8","metadata":{"execution":{"iopub.status.busy":"2024-08-24T04:52:33.172450Z","iopub.execute_input":"2024-08-24T04:52:33.173162Z","iopub.status.idle":"2024-08-24T04:52:33.184905Z","shell.execute_reply.started":"2024-08-24T04:52:33.173109Z","shell.execute_reply":"2024-08-24T04:52:33.184065Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Check for available GPUs\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Optionally set up multi-GPU training\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    vae = DataParallel(model)\n\n# Number of GPUs being used\nnum_devices = torch.cuda.device_count()\nprint(f\"Number of devices: {num_devices}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-24T04:52:33.186351Z","iopub.execute_input":"2024-08-24T04:52:33.186827Z","iopub.status.idle":"2024-08-24T04:52:33.197163Z","shell.execute_reply.started":"2024-08-24T04:52:33.186784Z","shell.execute_reply":"2024-08-24T04:52:33.196215Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Using device: cuda\nNumber of devices: 1\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model and store the results in \"history\" variable\nhistory = train(\n   model=model,\n   train_dataloader=train_dataloader,\n   test_dataloader=test_dataloader,\n   optimizer=optimizer,\n   loss_fn=loss,\n   epochs=100,\n   device=device,\n   patience=patience\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T04:52:33.198358Z","iopub.execute_input":"2024-08-24T04:52:33.199269Z","iopub.status.idle":"2024-08-24T05:01:10.336117Z","shell.execute_reply.started":"2024-08-24T04:52:33.199226Z","shell.execute_reply":"2024-08-24T05:01:10.334963Z"},"scrolled":true,"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"135it [00:50,  2.69it/s]\n34it [00:09,  3.67it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1 | train_loss: 6.1805 | train_acc: 0.3241 | train_F1_score: 0.1973 | train_recall: 0.3109 | train_precision: 0.1600 | val_loss: 1.4611 | val_acc: 0.4265 | val_F1_score: 0.2626 | val_recall: 0.3427 | val_precision: 0.2431\n","output_type":"stream"},{"name":"stderr","text":"\n135it [00:48,  2.79it/s]\n34it [00:08,  4.14it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2 | train_loss: 1.5949 | train_acc: 0.3074 | train_F1_score: 0.1830 | train_recall: 0.2935 | train_precision: 0.1473 | val_loss: 1.5842 | val_acc: 0.3015 | val_F1_score: 0.1600 | val_recall: 0.2647 | val_precision: 0.1201\nPatience counter: 1/8\n","output_type":"stream"},{"name":"stderr","text":"\n135it [00:48,  2.80it/s]\n34it [00:09,  3.60it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3 | train_loss: 1.5691 | train_acc: 0.3000 | train_F1_score: 0.1568 | train_recall: 0.2809 | train_precision: 0.1140 | val_loss: 1.5615 | val_acc: 0.3456 | val_F1_score: 0.1960 | val_recall: 0.3137 | val_precision: 0.1532\nPatience counter: 2/8\n","output_type":"stream"},{"name":"stderr","text":"\n135it [00:48,  2.79it/s]\n34it [00:08,  4.03it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4 | train_loss: 1.5423 | train_acc: 0.4000 | train_F1_score: 0.2249 | train_recall: 0.3475 | train_precision: 0.1776 | val_loss: 1.5432 | val_acc: 0.3456 | val_F1_score: 0.1960 | val_recall: 0.3137 | val_precision: 0.1532\nPatience counter: 3/8\n","output_type":"stream"},{"name":"stderr","text":"\n135it [00:48,  2.79it/s]\n34it [00:09,  3.74it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5 | train_loss: 1.5207 | train_acc: 0.3981 | train_F1_score: 0.2167 | train_recall: 0.3432 | train_precision: 0.1685 | val_loss: 1.5290 | val_acc: 0.3456 | val_F1_score: 0.1960 | val_recall: 0.3137 | val_precision: 0.1532\nPatience counter: 4/8\n","output_type":"stream"},{"name":"stderr","text":"\n135it [00:48,  2.80it/s]\n34it [00:08,  3.97it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6 | train_loss: 1.5047 | train_acc: 0.3963 | train_F1_score: 0.2178 | train_recall: 0.3290 | train_precision: 0.1730 | val_loss: 1.5184 | val_acc: 0.3456 | val_F1_score: 0.1960 | val_recall: 0.3137 | val_precision: 0.1532\nPatience counter: 5/8\n","output_type":"stream"},{"name":"stderr","text":"\n135it [00:48,  2.80it/s]\n34it [00:08,  4.08it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 7 | train_loss: 1.4909 | train_acc: 0.3981 | train_F1_score: 0.2098 | train_recall: 0.3432 | train_precision: 0.1602 | val_loss: 1.5103 | val_acc: 0.3456 | val_F1_score: 0.1960 | val_recall: 0.3137 | val_precision: 0.1532\nPatience counter: 6/8\n","output_type":"stream"},{"name":"stderr","text":"\n135it [00:48,  2.80it/s]\n34it [00:08,  3.84it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 8 | train_loss: 1.4801 | train_acc: 0.3981 | train_F1_score: 0.2286 | train_recall: 0.3512 | train_precision: 0.1810 | val_loss: 1.5047 | val_acc: 0.3456 | val_F1_score: 0.1960 | val_recall: 0.3137 | val_precision: 0.1532\nPatience counter: 7/8\n","output_type":"stream"},{"name":"stderr","text":"\n135it [00:48,  2.80it/s]\n34it [00:08,  3.83it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 9 | train_loss: 1.4707 | train_acc: 0.3981 | train_F1_score: 0.2244 | train_recall: 0.3432 | train_precision: 0.1781 | val_loss: 1.5006 | val_acc: 0.3456 | val_F1_score: 0.1960 | val_recall: 0.3137 | val_precision: 0.1532\nPatience counter: 8/8\nEarly stopping triggered.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Test ResNet50**","metadata":{}},{"cell_type":"code","source":"# Load pretrained ResNet50\nmodel = models.resnet50(pretrained=True)\nnum_features = model.fc.in_features\nmodel.fc = torch.nn.Linear(num_features, 5)  # Change the output features to 5","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:39:06.070299Z","iopub.execute_input":"2024-08-24T05:39:06.070618Z","iopub.status.idle":"2024-08-24T05:39:07.281836Z","shell.execute_reply.started":"2024-08-24T05:39:06.070587Z","shell.execute_reply":"2024-08-24T05:39:07.280966Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 189MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"model = torch.nn.DataParallel(model)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:39:07.283053Z","iopub.execute_input":"2024-08-24T05:39:07.283440Z","iopub.status.idle":"2024-08-24T05:39:07.370655Z","shell.execute_reply.started":"2024-08-24T05:39:07.283396Z","shell.execute_reply":"2024-08-24T05:39:07.369835Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Initialize optimizer, loss and device to train on\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))\nloss = nn.CrossEntropyLoss()\npatience=8\n\n# Check for available GPUs\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Optionally set up multi-GPU training\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    vae = DataParallel(model)\n\n# Number of GPUs being used\nnum_devices = torch.cuda.device_count()\nprint(f\"Number of devices: {num_devices}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:39:07.371739Z","iopub.execute_input":"2024-08-24T05:39:07.372040Z","iopub.status.idle":"2024-08-24T05:39:07.380347Z","shell.execute_reply.started":"2024-08-24T05:39:07.372008Z","shell.execute_reply":"2024-08-24T05:39:07.379477Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Using device: cuda\nUsing 2 GPUs\nNumber of devices: 2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model and store the results in \"history\" variable\nhistory = train(\n   model=model,\n   train_dataloader=train_dataloader,\n   test_dataloader=test_dataloader,\n   optimizer=optimizer,\n   loss_fn=loss,\n   epochs=100,\n   device=device,\n   patience=patience\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:39:07.383105Z","iopub.execute_input":"2024-08-24T05:39:07.383550Z","iopub.status.idle":"2024-08-24T06:06:09.282708Z","shell.execute_reply.started":"2024-08-24T05:39:07.383452Z","shell.execute_reply":"2024-08-24T06:06:09.281654Z"},"scrolled":true,"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n269it [02:13,  2.01it/s]\n68it [00:13,  5.02it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1 | train_loss: 1.5281 | train_acc: 0.3532 | train_F1_score: 0.2763 | train_recall: 0.3522 | train_precision: 0.2388 | val_loss: 1.4381 | val_acc: 0.4265 | val_F1_score: 0.3529 | val_recall: 0.4130 | val_precision: 0.3248\n","output_type":"stream"},{"name":"stderr","text":"\n269it [02:14,  2.00it/s]\n68it [00:13,  5.13it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2 | train_loss: 1.4854 | train_acc: 0.3569 | train_F1_score: 0.2800 | train_recall: 0.3538 | train_precision: 0.2441 | val_loss: 2.3445 | val_acc: 0.3750 | val_F1_score: 0.2990 | val_recall: 0.3750 | val_precision: 0.2610\nPatience counter: 1/8\n","output_type":"stream"},{"name":"stderr","text":"\n269it [02:14,  2.01it/s]\n68it [00:13,  5.12it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3 | train_loss: 1.5018 | train_acc: 0.3494 | train_F1_score: 0.2751 | train_recall: 0.3470 | train_precision: 0.2401 | val_loss: 1.4040 | val_acc: 0.5809 | val_F1_score: 0.5000 | val_recall: 0.5380 | val_precision: 0.4865\n","output_type":"stream"},{"name":"stderr","text":"\n269it [02:14,  2.01it/s]\n68it [00:13,  5.18it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4 | train_loss: 1.4668 | train_acc: 0.3810 | train_F1_score: 0.2924 | train_recall: 0.3804 | train_precision: 0.2485 | val_loss: 1.5496 | val_acc: 0.3750 | val_F1_score: 0.2990 | val_recall: 0.3750 | val_precision: 0.2610\nPatience counter: 1/8\n","output_type":"stream"},{"name":"stderr","text":"\n269it [02:14,  2.01it/s]\n68it [00:12,  5.26it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5 | train_loss: 1.4650 | train_acc: 0.3829 | train_F1_score: 0.3024 | train_recall: 0.3820 | train_precision: 0.2630 | val_loss: 5.8219 | val_acc: 0.3750 | val_F1_score: 0.2990 | val_recall: 0.3750 | val_precision: 0.2610\nPatience counter: 2/8\n","output_type":"stream"},{"name":"stderr","text":"\n269it [02:14,  2.01it/s]\n68it [00:13,  5.14it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6 | train_loss: 1.4478 | train_acc: 0.3680 | train_F1_score: 0.2887 | train_recall: 0.3659 | train_precision: 0.2506 | val_loss: 6.9061 | val_acc: 0.3750 | val_F1_score: 0.2990 | val_recall: 0.3750 | val_precision: 0.2610\nPatience counter: 3/8\n","output_type":"stream"},{"name":"stderr","text":"\n269it [02:13,  2.02it/s]\n68it [00:13,  5.00it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 7 | train_loss: 1.4671 | train_acc: 0.3885 | train_F1_score: 0.3135 | train_recall: 0.3835 | train_precision: 0.2794 | val_loss: 6.9368 | val_acc: 0.3750 | val_F1_score: 0.2990 | val_recall: 0.3750 | val_precision: 0.2610\nPatience counter: 4/8\n","output_type":"stream"},{"name":"stderr","text":"\n269it [02:13,  2.01it/s]\n68it [00:13,  5.20it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 8 | train_loss: 1.4617 | train_acc: 0.3829 | train_F1_score: 0.3061 | train_recall: 0.3829 | train_precision: 0.2677 | val_loss: 1.7425 | val_acc: 0.3750 | val_F1_score: 0.2990 | val_recall: 0.3750 | val_precision: 0.2610\nPatience counter: 5/8\n","output_type":"stream"},{"name":"stderr","text":"\n269it [02:14,  2.01it/s]\n68it [00:13,  5.21it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 9 | train_loss: 1.4511 | train_acc: 0.3810 | train_F1_score: 0.2962 | train_recall: 0.3783 | train_precision: 0.2556 | val_loss: 1.7073 | val_acc: 0.1176 | val_F1_score: 0.0784 | val_recall: 0.1005 | val_precision: 0.0748\nPatience counter: 6/8\n","output_type":"stream"},{"name":"stderr","text":"\n269it [02:14,  2.00it/s]\n68it [00:13,  5.14it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 10 | train_loss: 1.4432 | train_acc: 0.3736 | train_F1_score: 0.2962 | train_recall: 0.3662 | train_precision: 0.2639 | val_loss: 18.7196 | val_acc: 0.3750 | val_F1_score: 0.2990 | val_recall: 0.3750 | val_precision: 0.2610\nPatience counter: 7/8\n","output_type":"stream"},{"name":"stderr","text":"\n269it [02:13,  2.01it/s]\n68it [00:13,  5.17it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 11 | train_loss: 1.4457 | train_acc: 0.3941 | train_F1_score: 0.3086 | train_recall: 0.3848 | train_precision: 0.2723 | val_loss: 1.4451 | val_acc: 0.3750 | val_F1_score: 0.2990 | val_recall: 0.3750 | val_precision: 0.2610\nPatience counter: 8/8\nEarly stopping triggered.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}